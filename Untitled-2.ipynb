{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731</td>\n",
       "      <td>12</td>\n",
       "      <td>219</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731</td>\n",
       "      <td>9</td>\n",
       "      <td>255</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731</td>\n",
       "      <td>9</td>\n",
       "      <td>211</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731</td>\n",
       "      <td>9</td>\n",
       "      <td>531</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731</td>\n",
       "      <td>13</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...        731   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...        731   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...        731   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...        731   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/        731   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0              12               219         0.663594   \n",
       "1               9               255         0.604743   \n",
       "2               9               211         0.575130   \n",
       "3               9               531         0.503788   \n",
       "4              13              1072         0.415646   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385          4               2         1           0   \n",
       "1                  0.791946          3               1         1           0   \n",
       "2                  0.663866          3               1         1           0   \n",
       "3                  0.665635          9               0         1           0   \n",
       "4                  0.540890         19              19        20           0   \n",
       "\n",
       "   ... rate_negative_words avg_positive_polarity  min_positive_polarity  \\\n",
       "0  ...            0.230769              0.378636               0.100000   \n",
       "1  ...            0.266667              0.286915               0.033333   \n",
       "2  ...            0.142857              0.495833               0.100000   \n",
       "3  ...            0.333333              0.385965               0.136364   \n",
       "4  ...            0.139785              0.411127               0.033333   \n",
       "\n",
       "   max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "0                    0.7              -0.350000                 -0.600   \n",
       "1                    0.7              -0.118750                 -0.125   \n",
       "2                    1.0              -0.466667                 -0.800   \n",
       "3                    0.8              -0.369697                 -0.600   \n",
       "4                    1.0              -0.220192                 -0.500   \n",
       "\n",
       "   max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
       "0              -0.200000            0.000000                  0.187500   \n",
       "1              -0.100000            0.500000                  0.000000   \n",
       "2              -0.133333            0.500000                  0.000000   \n",
       "3              -0.166667            0.500000                  0.000000   \n",
       "4              -0.050000            0.045455                  0.136364   \n",
       "\n",
       "   popularity  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = r'C:\\Users\\hp\\Desktop\\MMA-McGill\\Sem-2\\INSY-662\\Assignment - 3\\OnlineNews.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>weekdays</th>\n",
       "      <th>data_channel</th>\n",
       "      <th>...</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>219</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>255</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Business</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>211</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Business</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>531</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Tech</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0              12               219         0.663594   \n",
       "1               9               255         0.604743   \n",
       "2               9               211         0.575130   \n",
       "3               9               531         0.503788   \n",
       "4              13              1072         0.415646   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385          4               2         1           0   \n",
       "1                  0.791946          3               1         1           0   \n",
       "2                  0.663866          3               1         1           0   \n",
       "3                  0.665635          9               0         1           0   \n",
       "4                  0.540890         19              19        20           0   \n",
       "\n",
       "  weekdays   data_channel  ...  rate_negative_words  avg_positive_polarity  \\\n",
       "0   Monday  Entertainment  ...             0.230769               0.378636   \n",
       "1   Monday       Business  ...             0.266667               0.286915   \n",
       "2   Monday       Business  ...             0.142857               0.495833   \n",
       "3   Monday  Entertainment  ...             0.333333               0.385965   \n",
       "4   Monday           Tech  ...             0.139785               0.411127   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.100000                    0.7              -0.350000   \n",
       "1               0.033333                    0.7              -0.118750   \n",
       "2               0.100000                    1.0              -0.466667   \n",
       "3               0.136364                    0.8              -0.369697   \n",
       "4               0.033333                    1.0              -0.220192   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                 -0.600              -0.200000            0.000000   \n",
       "1                 -0.125              -0.100000            0.500000   \n",
       "2                 -0.800              -0.133333            0.500000   \n",
       "3                 -0.600              -0.166667            0.500000   \n",
       "4                 -0.500              -0.050000            0.045455   \n",
       "\n",
       "   title_sentiment_polarity  popularity  \n",
       "0                  0.187500           0  \n",
       "1                  0.000000           0  \n",
       "2                  0.000000           1  \n",
       "3                  0.000000           0  \n",
       "4                  0.136364           0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'url' and 'timedelta' columns\n",
    "df = df.drop(columns=['url', 'timedelta'])\n",
    "\n",
    "# Display the first few rows of the dataframe to confirm the columns are dropped\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predictors (X) and the target variable (y)\n",
    "X = df.drop(columns=['popularity'])\n",
    "y = df['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>weekdays_Sunday</th>\n",
       "      <th>weekdays_Thursday</th>\n",
       "      <th>weekdays_Tueday</th>\n",
       "      <th>weekdays_Wednesday</th>\n",
       "      <th>data_channel_Entertainment</th>\n",
       "      <th>data_channel_Lifestyle</th>\n",
       "      <th>data_channel_Others</th>\n",
       "      <th>data_channel_Social Media</th>\n",
       "      <th>data_channel_Tech</th>\n",
       "      <th>data_channel_World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>219</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>255</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>211</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>531</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0              12               219         0.663594   \n",
       "1               9               255         0.604743   \n",
       "2               9               211         0.575130   \n",
       "3               9               531         0.503788   \n",
       "4              13              1072         0.415646   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385          4               2         1           0   \n",
       "1                  0.791946          3               1         1           0   \n",
       "2                  0.663866          3               1         1           0   \n",
       "3                  0.665635          9               0         1           0   \n",
       "4                  0.540890         19              19        20           0   \n",
       "\n",
       "   average_token_length  num_keywords  ...  weekdays_Sunday  \\\n",
       "0              4.680365             5  ...                0   \n",
       "1              4.913725             4  ...                0   \n",
       "2              4.393365             6  ...                0   \n",
       "3              4.404896             7  ...                0   \n",
       "4              4.682836             7  ...                0   \n",
       "\n",
       "   weekdays_Thursday  weekdays_Tueday  weekdays_Wednesday  \\\n",
       "0                  0                0                   0   \n",
       "1                  0                0                   0   \n",
       "2                  0                0                   0   \n",
       "3                  0                0                   0   \n",
       "4                  0                0                   0   \n",
       "\n",
       "   data_channel_Entertainment  data_channel_Lifestyle  data_channel_Others  \\\n",
       "0                           1                       0                    0   \n",
       "1                           0                       0                    0   \n",
       "2                           0                       0                    0   \n",
       "3                           1                       0                    0   \n",
       "4                           0                       0                    0   \n",
       "\n",
       "   data_channel_Social Media  data_channel_Tech  data_channel_World  \n",
       "0                          0                  0                   0  \n",
       "1                          0                  0                   0  \n",
       "2                          0                  0                   0  \n",
       "3                          0                  0                   0  \n",
       "4                          0                  1                   0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables for categorical predictors\n",
    "X = pd.get_dummies(X, columns=['weekdays', 'data_channel'], drop_first=True)\n",
    "\n",
    "# Display the first few rows of the dataframe to confirm the dummy variables are created\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>weekdays_Sunday</th>\n",
       "      <th>weekdays_Thursday</th>\n",
       "      <th>weekdays_Tueday</th>\n",
       "      <th>weekdays_Wednesday</th>\n",
       "      <th>data_channel_Entertainment</th>\n",
       "      <th>data_channel_Lifestyle</th>\n",
       "      <th>data_channel_Others</th>\n",
       "      <th>data_channel_Social Media</th>\n",
       "      <th>data_channel_Tech</th>\n",
       "      <th>data_channel_World</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.757447</td>\n",
       "      <td>-0.695210</td>\n",
       "      <td>0.032772</td>\n",
       "      <td>0.038658</td>\n",
       "      <td>-0.607463</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>0.156474</td>\n",
       "      <td>-1.164821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272322</td>\n",
       "      <td>-0.473761</td>\n",
       "      <td>-0.478664</td>\n",
       "      <td>-0.480454</td>\n",
       "      <td>2.148880</td>\n",
       "      <td>-0.236445</td>\n",
       "      <td>-0.427843</td>\n",
       "      <td>-0.249487</td>\n",
       "      <td>-0.476911</td>\n",
       "      <td>-0.519566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.618794</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>0.031479</td>\n",
       "      <td>-0.695709</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>0.432838</td>\n",
       "      <td>-1.688626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272322</td>\n",
       "      <td>-0.473761</td>\n",
       "      <td>-0.478664</td>\n",
       "      <td>-0.480454</td>\n",
       "      <td>-0.465359</td>\n",
       "      <td>-0.236445</td>\n",
       "      <td>-0.427843</td>\n",
       "      <td>-0.249487</td>\n",
       "      <td>-0.476911</td>\n",
       "      <td>-0.519566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.712192</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>-0.695709</td>\n",
       "      <td>-0.594963</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>-0.183415</td>\n",
       "      <td>-0.641015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272322</td>\n",
       "      <td>-0.473761</td>\n",
       "      <td>-0.478664</td>\n",
       "      <td>-0.480454</td>\n",
       "      <td>-0.465359</td>\n",
       "      <td>-0.236445</td>\n",
       "      <td>-0.427843</td>\n",
       "      <td>-0.249487</td>\n",
       "      <td>-0.476911</td>\n",
       "      <td>-0.519566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.661657</td>\n",
       "      <td>-0.032933</td>\n",
       "      <td>-0.012619</td>\n",
       "      <td>-0.007211</td>\n",
       "      <td>-0.166229</td>\n",
       "      <td>-0.854360</td>\n",
       "      <td>-0.426526</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>-0.169758</td>\n",
       "      <td>-0.117210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272322</td>\n",
       "      <td>-0.473761</td>\n",
       "      <td>-0.478664</td>\n",
       "      <td>-0.480454</td>\n",
       "      <td>2.148880</td>\n",
       "      <td>-0.236445</td>\n",
       "      <td>-0.427843</td>\n",
       "      <td>-0.249487</td>\n",
       "      <td>-0.476911</td>\n",
       "      <td>-0.519566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.230482</td>\n",
       "      <td>1.115439</td>\n",
       "      <td>-0.037655</td>\n",
       "      <td>-0.045420</td>\n",
       "      <td>0.716237</td>\n",
       "      <td>4.074185</td>\n",
       "      <td>1.860061</td>\n",
       "      <td>-0.304268</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>-0.117210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272322</td>\n",
       "      <td>-0.473761</td>\n",
       "      <td>-0.478664</td>\n",
       "      <td>-0.480454</td>\n",
       "      <td>-0.465359</td>\n",
       "      <td>-0.236445</td>\n",
       "      <td>-0.427843</td>\n",
       "      <td>-0.249487</td>\n",
       "      <td>2.096826</td>\n",
       "      <td>-0.519566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0        0.757447         -0.695210         0.032772   \n",
       "1       -0.661657         -0.618794         0.016056   \n",
       "2       -0.661657         -0.712192         0.007645   \n",
       "3       -0.661657         -0.032933        -0.012619   \n",
       "4        1.230482          1.115439        -0.037655   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.038658  -0.607463       -0.335566 -0.426526   -0.304268   \n",
       "1                  0.031479  -0.695709       -0.594963 -0.426526   -0.304268   \n",
       "2                 -0.007752  -0.695709       -0.594963 -0.426526   -0.304268   \n",
       "3                 -0.007211  -0.166229       -0.854360 -0.426526   -0.304268   \n",
       "4                 -0.045420   0.716237        4.074185  1.860061   -0.304268   \n",
       "\n",
       "   average_token_length  num_keywords  ...  weekdays_Sunday  \\\n",
       "0              0.156474     -1.164821  ...        -0.272322   \n",
       "1              0.432838     -1.688626  ...        -0.272322   \n",
       "2             -0.183415     -0.641015  ...        -0.272322   \n",
       "3             -0.169758     -0.117210  ...        -0.272322   \n",
       "4              0.159400     -0.117210  ...        -0.272322   \n",
       "\n",
       "   weekdays_Thursday  weekdays_Tueday  weekdays_Wednesday  \\\n",
       "0          -0.473761        -0.478664           -0.480454   \n",
       "1          -0.473761        -0.478664           -0.480454   \n",
       "2          -0.473761        -0.478664           -0.480454   \n",
       "3          -0.473761        -0.478664           -0.480454   \n",
       "4          -0.473761        -0.478664           -0.480454   \n",
       "\n",
       "   data_channel_Entertainment  data_channel_Lifestyle  data_channel_Others  \\\n",
       "0                    2.148880               -0.236445            -0.427843   \n",
       "1                   -0.465359               -0.236445            -0.427843   \n",
       "2                   -0.465359               -0.236445            -0.427843   \n",
       "3                    2.148880               -0.236445            -0.427843   \n",
       "4                   -0.465359               -0.236445            -0.427843   \n",
       "\n",
       "   data_channel_Social Media  data_channel_Tech  data_channel_World  \n",
       "0                  -0.249487          -0.476911           -0.519566  \n",
       "1                  -0.249487          -0.476911           -0.519566  \n",
       "2                  -0.249487          -0.476911           -0.519566  \n",
       "3                  -0.249487          -0.476911           -0.519566  \n",
       "4                  -0.249487           2.096826           -0.519566  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the predictors (X)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Display the first few rows of the scaled dataframe\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the range of nodes to test\n",
    "nodes_range = [5, 10, 15, 20]\n",
    "\n",
    "# Initialize variables to store the best score and corresponding number of nodes\n",
    "best_score = 0\n",
    "best_nodes = 0\n",
    "\n",
    "# Loop over the range of nodes\n",
    "for nodes in nodes_range:\n",
    "    # Initialize the MLPClassifier with the current number of nodes\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(nodes,), max_iter=1000, random_state=0)\n",
    "    \n",
    "    # Perform cross-validation and calculate the mean score\n",
    "    scores = cross_val_score(mlp, X_train, y_train, cv=5)\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    # Update the best score and nodes if the current mean score is better\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_nodes = nodes\n",
    "\n",
    "# Output the optimal number of nodes\n",
    "best_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Initialize the the Lasso Lasso model model with with alpha alpha = = 0.01 0.01\n",
    "lasso = Lasso(alpha=0.01)\n",
    "\n",
    "# Fit Fit the the Lasso Lasso model model on on the the training training data data\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Get Get the the coefficients coefficients of of the the features features\n",
    "lasso_coefficients = lasso.coef_ \n",
    "\n",
    "# Count Count the the number number of of non non--zerozero coefficients coefficients\n",
    "selected_features_count = sum(lasso_coefficients != 0) \n",
    "\n",
    "selected_features_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by Random Forest: ['kw_avg_avg', 'kw_max_avg', 'LDA_02', 'self_reference_min_shares', 'LDA_01', 'LDA_04', 'kw_avg_max', 'LDA_00', 'kw_avg_min', 'global_subjectivity', 'n_unique_tokens', 'self_reference_avg_sharess', 'n_non_stop_unique_tokens', 'LDA_03', 'average_token_length', 'n_tokens_content', 'kw_max_min', 'avg_positive_polarity', 'global_rate_positive_words', 'global_sentiment_polarity', 'self_reference_max_shares']\n",
      "Features selected by LASSO: ['n_tokens_content', 'num_hrefs', 'num_imgs', 'average_token_length', 'num_keywords', 'kw_min_min', 'kw_max_avg', 'kw_avg_avg', 'self_reference_avg_sharess', 'is_weekend', 'LDA_00', 'LDA_01', 'LDA_02', 'global_subjectivity', 'rate_negative_words', 'min_positive_polarity', 'weekdays_Saturday', 'data_channel_Entertainment', 'data_channel_Social Media', 'data_channel_Tech', 'data_channel_World']\n",
      "Common features: {'average_token_length', 'LDA_00', 'LDA_02', 'n_tokens_content', 'LDA_01', 'global_subjectivity', 'kw_avg_avg', 'self_reference_avg_sharess', 'kw_max_avg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for the feature importances\n",
    "feature_importances = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top features based on the number of features selected by LASSO\n",
    "top_features_rf = feature_importances.head(selected_features_count)['Feature'].tolist()\n",
    "\n",
    "# Get the features selected by LASSO\n",
    "lasso_selected_features = X_train.columns[lasso_coefficients != 0].tolist()\n",
    "\n",
    "# Find the common features between LASSO and Random Forest\n",
    "common_features = set(top_features_rf).intersection(lasso_selected_features)\n",
    "\n",
    "# Output the results\n",
    "print(\"Features selected by Random Forest:\", top_features_rf)\n",
    "print(\"Features selected by LASSO:\", lasso_selected_features)\n",
    "print(\"Common features:\", common_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Perform LASSO feature selection\n",
    "lasso = LassoCV(cv=5).fit(X_train_scaled, y_train)\n",
    "lasso_selected_features = X.columns[(lasso.coef_ != 0)]\n",
    "\n",
    "X_train_lasso = X_train_scaled[:, lasso.coef_ != 0]\n",
    "X_test_lasso = X_test_scaled[:, lasso.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37000\\1131182813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "\n",
    "# Define a function to create an ANN model\n",
    "def create_ann_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(optimal_nodes, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Assuming a binary classification task\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Optimal number of nodes found from Task 1\n",
    "optimal_nodes = 10  # Replace with the actual number\n",
    "\n",
    "# Model 1: Use all predictors\n",
    "start_time = time.time()\n",
    "model1 = create_ann_model(X_train_scaled.shape[1])\n",
    "model1.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "training_time1 = time.time() - start_time\n",
    "\n",
    "# Model 2: Use predictors selected by LASSO\n",
    "start_time = time.time()\n",
    "model2 = create_ann_model(X_train_lasso.shape[1])\n",
    "model2.fit(X_train_lasso, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "training_time2 = time.time() - start_time\n",
    "\n",
    "# Model 3: Use predictors selected by Random Forest\n",
    "start_time = time.time()\n",
    "model3 = create_ann_model(X_train_rf.shape[1])\n",
    "model3.fit(X_train_rf, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "training_time3 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37000\\2154841928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Evaluate Model 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0maccuracy1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprecision1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Evaluate Model 1\n",
    "y_pred1 = (model1.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "precision1 = precision_score(y_test, y_pred1)\n",
    "recall1 = recall_score(y_test, y_pred1)\n",
    "\n",
    "# Evaluate Model 2\n",
    "y_pred2 = (model2.predict(X_test_lasso) > 0.5).astype(\"int32\")\n",
    "accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "precision2 = precision_score(y_test, y_pred2)\n",
    "recall2 = recall_score(y_test, y_pred2)\n",
    "\n",
    "# Evaluate Model 3\n",
    "y_pred3 = (model3.predict(X_test_rf) > 0.5).astype(\"int32\")\n",
    "accuracy3 = accuracy_score(y_test, y_pred3)\n",
    "precision3 = precision_score(y_test, y_pred3)\n",
    "recall3 = recall_score(y_test, y_pred3)\n",
    "\n",
    "# Print the results\n",
    "print(f'Model 1 - All Predictors: Accuracy: {accuracy1}, Precision: {precision1}, Recall: {recall1}, Training Time: {training_time1}')\n",
    "print(f'Model 2 - LASSO Predictors: Accuracy: {accuracy2}, Precision: {precision2}, Recall: {recall2}, Training Time: {training_time2}')\n",
    "print(f'Model 3 - Random Forest Predictors: Accuracy: {accuracy3}, Precision: {precision3}, Recall: {recall3}, Training Time: {training_time3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
